Mon Apr 15 18:46:12 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-80GB           On | 00000000:81:00.0 Off |                    0 |
| N/A   29C    P0               59W / 500W|      0MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
torchrun --nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 51625 /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//evaluate.py --base-path /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm/ --model-path /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//checkpoints/t5-base/ --ckpt-name t5-base --n-gpu 1 --model-type gpt2 --data-dir /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//data/dolly/full/gpt2/ --data-names dolly --num-workers 0 --dev-num -1 --data-process-workers -1 --json-data --eval-batch-size 16 --max-length 512 --max-prompt-length 256 --do-eval --save /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//results/t5-base/eval_main/ --seed 10 --deepspeed --deepspeed_config /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//configs/deepspeed/ds_config.json --type eval_main --do-sample --top-k 0 --top-p 1.0 --temperature 1.0
PYTHONPATH=/home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm/
[2024-04-15 18:46:17,356] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[nltk_data] Downloading package punkt to
[nltk_data]     /home/student/f/fklinge/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /home/student/f/fklinge/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 1
[2024-04-15 18:46:19,577] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-04-15 18:46:19,578] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-04-15 18:46:19,578] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//checkpoints/t5-base/
  ckpt_name .................... t5-base
  model_type ................... gpt2
  teacher_model_type ........... None
  n_gpu ........................ 1
  n_nodes ...................... 1
  teacher_model_path ........... None
  teacher_ckpt_name ............ None
  teacher_model_fp16 ........... False
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  fp32 ......................... False
  type ......................... eval_main
  do_train ..................... False
  do_valid ..................... False
  do_eval ...................... True
  base_path .................... /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm/
  load ......................... None
  save ......................... /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//results/t5-base/eval_main/dolly-512/t5-base/10
  log_interval ................. 10
  mid_log_num .................. 4
  save_interval ................ 1000
  eval_interval ................ 1000
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//data/dolly/full/gpt2/
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... -1
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... dolly
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 256
  min_prompt_length ............ 128
  json_data .................... True
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. None
  lm_data_dir .................. None
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... False
  only_prompt .................. False
  batch_size ................... 32
  eval_batch_size .............. 16
  clip_grad .................... 1.0
  total_iters .................. None
  train_iters_per_epoch ........ -1
  max_length ................... 512
  seed ......................... 10
  seed_order ................... 42
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... None
  training_epochs .............. 10000
  gradient_accumulation_steps .. 1
  gradient_checkpointing ....... False
  attn_dtype ................... None
  lr ........................... None
  lr_min ....................... 1e-07
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... None
  warmup_iters ................. 0
  lr_decay_iters ............... None
  lr_decay_style ............... noam
  scheduler_name ............... constant_trm
  reward_scaling ............... None
  cliprange_reward ............. 1
  ppo_epochs ................... None
  num_rollouts ................. 256
  num_rollouts_per_device ...... None
  cliprange .................... 0.2
  chunk_size ................... None
  gamma ........................ 0.95
  length_norm .................. False
  single_step_reg .............. False
  teacher_mixed_alpha .......... None
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. /home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  rank ......................... 0
  world_size ................... 1
OK
Loading Data
  0%|          | 0/1000 [00:00<?, ?it/s] 27%|██▋       | 271/1000 [00:00<00:00, 2694.14it/s] 54%|█████▍    | 541/1000 [00:00<00:00, 2643.34it/s] 81%|████████  | 806/1000 [00:00<00:00, 2613.47it/s]100%|██████████| 1000/1000 [00:00<00:00, 2613.31it/s]
Load End
Num instances: 1000
 > number of parameters: 222903552
Model load time: 5.416397333145142s
[2024-04-15 18:46:25,726] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2024-04-15 18:46:27,256] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-15 18:46:27,258] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2024-04-15 18:46:27,259] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-04-15 18:46:27,260] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-15 18:46:27,260] [INFO] [config.py:964:print]   amp_enabled .................. False
[2024-04-15 18:46:27,261] [INFO] [config.py:964:print]   amp_params ................... False
[2024-04-15 18:46:27,261] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-15 18:46:27,262] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2024-04-15 18:46:27,262] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2024-04-15 18:46:27,263] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2024-04-15 18:46:27,263] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2024-04-15 18:46:27,263] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x150d54817df0>
[2024-04-15 18:46:27,264] [INFO] [config.py:964:print]   communication_data_type ...... None
[2024-04-15 18:46:27,264] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-15 18:46:27,265] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2024-04-15 18:46:27,265] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2024-04-15 18:46:27,266] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-15 18:46:27,266] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2024-04-15 18:46:27,266] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2024-04-15 18:46:27,267] [INFO] [config.py:964:print]   disable_allgather ............ False
[2024-04-15 18:46:27,267] [INFO] [config.py:964:print]   dump_state ................... False
[2024-04-15 18:46:27,268] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-15 18:46:27,268] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2024-04-15 18:46:27,268] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-15 18:46:27,269] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-15 18:46:27,269] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2024-04-15 18:46:27,270] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2024-04-15 18:46:27,270] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2024-04-15 18:46:27,270] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2024-04-15 18:46:27,271] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2024-04-15 18:46:27,271] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2024-04-15 18:46:27,272] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-04-15 18:46:27,272] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2024-04-15 18:46:27,272] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2024-04-15 18:46:27,273] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2024-04-15 18:46:27,273] [INFO] [config.py:964:print]   global_rank .................. 0
[2024-04-15 18:46:27,274] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2024-04-15 18:46:27,274] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2024-04-15 18:46:27,274] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2024-04-15 18:46:27,274] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2024-04-15 18:46:27,275] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-15 18:46:27,275] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2024-04-15 18:46:27,276] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2024-04-15 18:46:27,276] [INFO] [config.py:964:print]   loss_scale ................... 0
[2024-04-15 18:46:27,277] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2024-04-15 18:46:27,277] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2024-04-15 18:46:27,277] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2024-04-15 18:46:27,278] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-15 18:46:27,278] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-04-15 18:46:27,279] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2024-04-15 18:46:27,279] [INFO] [config.py:964:print]   optimizer_name ............... None
[2024-04-15 18:46:27,280] [INFO] [config.py:964:print]   optimizer_params ............. None
[2024-04-15 18:46:27,280] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-15 18:46:27,281] [INFO] [config.py:964:print]   pld_enabled .................. False
[2024-04-15 18:46:27,281] [INFO] [config.py:964:print]   pld_params ................... False
[2024-04-15 18:46:27,281] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2024-04-15 18:46:27,282] [INFO] [config.py:964:print]   scheduler_name ............... None
[2024-04-15 18:46:27,282] [INFO] [config.py:964:print]   scheduler_params ............. None
[2024-04-15 18:46:27,283] [INFO] [config.py:964:print]   sparse_attention ............. None
[2024-04-15 18:46:27,283] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2024-04-15 18:46:27,284] [INFO] [config.py:964:print]   steps_per_print .............. 1
[2024-04-15 18:46:27,284] [INFO] [config.py:964:print]   train_batch_size ............. 32
[2024-04-15 18:46:27,284] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  32
[2024-04-15 18:46:27,285] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2024-04-15 18:46:27,285] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2024-04-15 18:46:27,286] [INFO] [config.py:964:print]   world_size ................... 1
[2024-04-15 18:46:27,286] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2024-04-15 18:46:27,286] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2024-04-15 18:46:27,287] [INFO] [config.py:964:print]   zero_enabled ................. False
[2024-04-15 18:46:27,287] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-15 18:46:27,288] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2024-04-15 18:46:27,288] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 32, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 453343 KiB | 453343 KiB | 453343 KiB |      0 B   |
|       from large pool | 453248 KiB | 453248 KiB | 453248 KiB |      0 B   |
|       from small pool |     95 KiB |     95 KiB |     95 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         | 453343 KiB | 453343 KiB | 453343 KiB |      0 B   |
|       from large pool | 453248 KiB | 453248 KiB | 453248 KiB |      0 B   |
|       from small pool |     95 KiB |     95 KiB |     95 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      | 435358 KiB | 435358 KiB | 435358 KiB |      0 B   |
|       from large pool | 435264 KiB | 435264 KiB | 435264 KiB |      0 B   |
|       from small pool |     94 KiB |     94 KiB |     94 KiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 460800 KiB | 460800 KiB | 460800 KiB |      0 B   |
|       from large pool | 458752 KiB | 458752 KiB | 458752 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |   7457 KiB |  22242 KiB | 343679 KiB | 336222 KiB |
|       from large pool |   5504 KiB |  20224 KiB | 341632 KiB | 336128 KiB |
|       from small pool |   1953 KiB |   2047 KiB |   2047 KiB |     94 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     257    |     257    |     257    |       0    |
|       from large pool |     193    |     193    |     193    |       0    |
|       from small pool |      64    |      64    |      64    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     257    |     257    |     257    |       0    |
|       from large pool |     193    |     193    |     193    |       0    |
|       from small pool |      64    |      64    |      64    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      22    |      22    |      22    |       0    |
|       from large pool |      21    |      21    |      21    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       3    |      21    |      19    |
|       from large pool |       1    |       2    |      20    |      19    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating dolly :   0%|          | 0/63 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: Give me a chronological bulleted list based on a timeline of events ### Input: Olson served as a law clerk for Judge Barbara Jacobs Rothstein on the United States District Court for the Western District of Washington for two years immediately after finishing law school. She served as a trial attorney and later Deputy Director of the National Church Arson Task Force in the United States Department of Justice Civil Rights Division from 1992 to 1997. From 1994 to 1997, she also worked part-time as an adjunct professor at George Washington University Law School. In 1997, Olson joined the Office of the United States Attorney for the District of Idaho, rising to the rank of Senior Litigation Counsel at the time of her appointment in 2010.[4] After Olson resigned in 2017, she joined the Boise office of Stoel Rives, a law firm that operates in the Pacific Northwest.[5][6] In 2021, Olson was included on a shortlist of possible nominees to succeed Judge B. Lynn Winmill.[
############### End ###############
Evaluating dolly :   0%|          | 0/63 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//evaluate.py", line 104, in <module>
    main()
  File "/home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//evaluate.py", line 96, in main
    evaluate_main(args, tokenizer, model, dataset["test"], "test", 0, device)
  File "/share/users/student/f/fklinge/bachelor/ichteste/LMOps/minillm/evaluate_main.py", line 137, in evaluate_main
    lm_loss, query_ids, response_ids = run_model(args, tokenizer, model, dataset, epoch, device)
  File "/share/users/student/f/fklinge/bachelor/ichteste/LMOps/minillm/evaluate_main.py", line 84, in run_model
    out = model(input_ids=input_ids, position_ids=position_ids, attention_mask=attention_mask, return_dict=True)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1769, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: forward() got an unexpected keyword argument 'position_ids'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 238813) of binary: /home/student/f/fklinge/.conda/envs/test3/bin/python
Traceback (most recent call last):
  File "/home/student/f/fklinge/.conda/envs/test3/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/student/f/fklinge/.conda/envs/test3/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/student/f/fklinge/share/bachelor/ichteste/LMOps/minillm//evaluate.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-15_18:46:30
  host      : hpc3-53.hpc
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 238813)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
